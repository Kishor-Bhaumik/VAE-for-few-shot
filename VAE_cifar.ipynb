{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Cifar_.ipynb","provenance":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"F6SEu5e6tZ9h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607795524335,"user_tz":-360,"elapsed":39344,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii83h-fRBFEuQ-QSk7eC3q25ZuTIxZnGI7Z_us=s64","userId":"10041133773810708456"}},"outputId":"190687b4-0f66-4c86-8e88-f7023df7474d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IhRYycjXvsJ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607795739263,"user_tz":-360,"elapsed":2023,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii83h-fRBFEuQ-QSk7eC3q25ZuTIxZnGI7Z_us=s64","userId":"10041133773810708456"}},"outputId":"1ad00d60-56f5-471c-ba29-f9ed88ce979c"},"source":["cd 'drive/My Drive/Colab Notebooks/iub_drive/cam/cifar/dth'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/iub_drive/cam/cifar/dth\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3b5QMclzGM__","executionInfo":{"status":"ok","timestamp":1607795807279,"user_tz":-360,"elapsed":4043,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii83h-fRBFEuQ-QSk7eC3q25ZuTIxZnGI7Z_us=s64","userId":"10041133773810708456"}},"outputId":"5802c7a1-24e9-42d0-e9a8-75c3fc3a8972"},"source":["!pip install numpy_indexed"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting numpy_indexed\n","  Downloading https://files.pythonhosted.org/packages/4c/90/fe830d577400954db57a88f7022efef095745e1df4256ca5171d659d4177/numpy_indexed-0.3.5-py2.py3-none-any.whl\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from numpy_indexed) (0.16.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from numpy_indexed) (1.18.5)\n","Installing collected packages: numpy-indexed\n","Successfully installed numpy-indexed-0.3.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0MRNztGPGCzB","executionInfo":{"status":"ok","timestamp":1607795830940,"user_tz":-360,"elapsed":19997,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gii83h-fRBFEuQ-QSk7eC3q25ZuTIxZnGI7Z_us=s64","userId":"10041133773810708456"}},"outputId":"551c84eb-caa1-457e-a1a3-63e004753529"},"source":["!python process.py"],"execution_count":5,"outputs":[{"output_type":"stream","text":["tcmalloc: large alloc 1229201408 bytes == 0x17bf2000 @  0x7f20b6f2f1e7 0x7f20b4a955e1 0x7f20b4af9c78 0x7f20b4af9d93 0x7f20b4b97ea8 0x7f20b4b98704 0x7f20b4b98852 0x566f73 0x59fd0e 0x7f20b4ae54ed 0x50a12f 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x588e5c 0x59fd0e 0x7f20b4ae54ed 0x50a12f 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x50ad03 0x634e72 0x634f27 0x6386df\n","tcmalloc: large alloc 1475043328 bytes == 0x6faa8000 @  0x7f20b6f2f1e7 0x7f20b4a955e1 0x7f20b4af9c78 0x7f20b4af9d93 0x7f20b4b97ea8 0x7f20b4b98704 0x7f20b4b98852 0x566f73 0x59fd0e 0x7f20b4ae54ed 0x50a12f 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x588e5c 0x59fd0e 0x7f20b4ae54ed 0x50a12f 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x50ad03 0x634e72 0x634f27 0x6386df\n","tcmalloc: large alloc 1475526656 bytes == 0xc795e000 @  0x7f20b6f2f1e7 0x7f20b4a955e1 0x7f20b4af9c78 0x7f20b4af9d93 0x7f20b4b97ea8 0x7f20b4b98704 0x7f20b4b98852 0x566f73 0x59fd0e 0x7f20b4ae54ed 0x50a12f 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x588e5c 0x59fd0e 0x7f20b4ae54ed 0x50a12f 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50cc96 0x507be4 0x50ad03 0x634e72 0x634f27 0x6386df\n","data saved \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ESAXPMTctxMS"},"source":["import time\n","start= time.time()\n","\n","import torch\n","from torchvision import datasets\n","import numpy as np\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim \n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","from torchsummary import summary\n","from torch.autograd import Variable\n","from torch.backends import cudnn\n","from multiprocessing import Pool\n","import cv2 \n","from torchvision import transforms, utils\n","from torch.utils import data\n","from sklearn.model_selection import train_test_split\n","import random \n","torch.nn.Module.dump_patches = True\n","\n","import os, glob\n","import csv\n","\n","SEED=42\n","cudnn.benchmark = True\n","trainL=[0,1,2,3,4,5,6,7]\n","testL= [8,9]\n","use_cuda = torch.cuda.is_available()\n","bs=64\n","device = torch.device('cuda' if use_cuda else \"cpu\")\n","#device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","class_total=len(trainL)\n","\n","random.seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","\n","with open('data/all_cifar.npy', 'rb') as f:\n","    q= np.load(f)\n","\n","def getData(Q):\n","    \n","    for i,val in enumerate(Q):\n","\n","        if i is 0: loader= q[val, :, :]\n","        else :\n","            add=q[val, :, :]\n","            loader=np.append(loader,add,axis=0)\n","    \n","    return loader\n"," \n","train=getData(trainL)\n","\n","\n","x_train, x_test, y_train, y_test = train_test_split(train[:,1:], train[:, 0], test_size=0.2, random_state=42)\n","\n","np.save(\"data/novel_test.npy\",x_test)\n","np.save(\"data/novel_label.npy\", y_test)\n","\n","transform = transforms.Compose([\n","    transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","class CIFAR(Dataset):\n","    def __init__(self, images, labels=None, transforms=None):\n","        self.X = images\n","        self.y = labels\n","        self.transforms = transforms\n","         \n","    def __len__(self):\n","        return (len(self.X))\n","    \n","    def __getitem__(self, i):\n","        data = self.X[i, :]\n","        data = data.astype(np.uint8).reshape(32,32,3)\n","        \n","        if self.transforms:\n","            data = self.transforms(data)\n","            \n","        if self.y is not None:\n","            return (data, self.y[i])\n","        else:\n","            return data\n"," \n","\n","train_data = CIFAR(x_train, y_train, transform)\n","trainloader = DataLoader(train_data, batch_size=bs, shuffle=True ,pin_memory=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ClsJyGkWuGQ6"},"source":["import torch.nn as nn\n","import torch.utils.model_zoo as model_zoo\n","import math\n","\n","\n","class VGG(nn.Module):\n","\n","    def __init__(self, features, num_classes=1000):\n","        super(VGG, self).__init__()\n","        self.features = features\n","        self.classifier = nn.Sequential(\n","            nn.Linear(512 * 7 * 7, 4096),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, 4096),\n","            nn.ReLU(True),\n","            nn.Dropout(),\n","            nn.Linear(4096, num_classes),\n","        )\n","        self._initialize_weights()\n","\n","    def forward(self, x):\n","        x = self.features(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.classifier(x)\n","        return x\n","\n","    def _initialize_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","                if m.bias is not None:\n","                    m.bias.data.zero_()\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","            elif isinstance(m, nn.Linear):\n","                m.weight.data.normal_(0, 0.01)\n","                m.bias.data.zero_()\n","\n","\n","def make_layers(cfg, batch_norm=False):\n","    layers = []\n","    in_channels = 3\n","    for v in cfg:\n","        if v == 'M':\n","            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n","        else:\n","            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n","            if batch_norm:\n","                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n","            else:\n","                layers += [conv2d, nn.ReLU(inplace=True)]\n","            in_channels = v\n","    return nn.Sequential(*layers)\n","\n","\n","cfg = {\n","    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}\n","\n","def vgg16(STR, **kwargs):\n","    \"\"\"VGG 16-layer model (configuration \"D\")\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = VGG(make_layers(cfg['D']), **kwargs)\n","\n","    model.load_state_dict(torch.load(STR))\n","    return model\n","\n","\n","PATH='vgg16-397923af.pth'\n","\n","model_vgg = vgg16(PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hSDqRPuSCxI9","colab":{"base_uri":"https://localhost:8080/","height":781},"executionInfo":{"status":"ok","timestamp":1594221499521,"user_tz":-360,"elapsed":1512,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"354351b1-e141-4ccf-f0c1-36bfa08182cf"},"source":["model_vgg"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (18): ReLU(inplace=True)\n","    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (25): ReLU(inplace=True)\n","    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (27): ReLU(inplace=True)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"zbfnRsmSuG2r","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594278872596,"user_tz":-360,"elapsed":1553945,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"97239085-447a-47de-9b04-a0c630256c3e"},"source":["class custom_vgg (nn.Module):\n","    def __init__(self):\n","        super(custom_vgg,self).__init__()\n","        #self.features = model_vgg.features\n","        self.features2= model_vgg.features[:15]\n","        #self.features_vae = model.features\n","        #self.bn2 =nn.BatchNorm2d(512)\n","        self.global_avg_pool = nn.AvgPool2d(kernel_size=(7,7))\n","        self.drop = nn.Dropout(0.7)\n","        self.fc = nn.Linear(256,class_total)\n","#         self.soft = nn.Softmax(dim = 1)\n","        \n","    def forward(self,x):\n","        #c1 = self.features(x)\n","        Cnew=self.features2(x)\n","        c3 = self.global_avg_pool(Cnew)\n","        #print(Cnew.shape)\n","        c4 = c3.view(-1,256)\n","        \n","        c5 = self.drop(c4)\n","        out = self.fc(c5)\n","#         out = self.soft(c6)\n","        return Cnew, out # F.relu(Cnew), out  \n","\n","class VAE(nn.Module):\n","    def __init__(self,inp,hidden,latent_variable_size):\n","        super(VAE, self).__init__()\n","\n","        self.INP=inp\n","        self.hidden = hidden\n","        self.latent_variable_size = latent_variable_size\n","        self.bn = nn.BatchNorm1d(16384)\n","        self.fc1 = nn.Linear(inp, hidden)\n","        self.fc21 = nn.Linear(hidden, latent_variable_size)\n","        self.fc22 = nn.Linear(hidden, latent_variable_size)\n","        self.fc3 = nn.Linear(latent_variable_size, hidden)\n","        self.fc4 = nn.Linear(hidden, inp)\n","\n","    def weight_init(self):\n","        for block in self._modules:\n","            try:\n","                for m in self._modules[block]:\n","                    normal_init(m)\n","            except:\n","                normal_init(block)\n","    def encode(self, x):\n","        h1 = F.relu(self.fc1(x))\n","        return self.fc21(h1), self.fc22(h1)\n","\n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5*logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps*std\n","\n","    def decode(self, z):\n","        h3 = F.relu(self.fc3(z))\n","        v=torch.sigmoid(self.fc4(h3))\n","        return v.reshape(v.size(0),256,8,8)\n","\n","    def forward(self, x):\n","        x=x.reshape(x.size(0),-1)\n","        x=self.bn(x)\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu, logvar)\n","        return self.decode(z), mu, logvar\n","    \n","    \n","    \n","def loss_function(recon_x, x, mu, logvar):\n","    #BCE =F.binary_cross_entropy(recon_x, x, reduction='sum')\n","    BCE=F.mse_loss(recon_x, x)\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","    #kld= crit(recon_x, x)\n","    \n","    return BCE + KLD ,BCE,KLD\n","\n","\n","model =custom_vgg()\n","model.to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","vae_loss=[]\n","epoch_loss=[]\n","#model_vae = VAE(inp=512*7*7,hidden=5000,latent_variable_size=1000).to(device)\n","#model_vae = VAE(512*7*7,5000,100)\n","model_vae = VAE(16384,5000,100)\n","#model_vae.apply(init_weights)\n","model_vae.to(device)\n","\n","optimizer_vae = optim.Adam(model_vae.parameters(), lr=1e-4)\n","#optimizer_vae = optim.SGD(model_vae.parameters(), lr=1e-3)\n","max_epochs = 20\n","model.train()\n","model_vae.train()\n","\n","train_loss_min = np.Inf \n","for epoch in range(max_epochs):\n","    train_loss = 0.0\n","    cn = 0\n","    epoch_losssss = 0\n","    acc = 0\n","    vae_train_loss=0\n","    bnce=0\n","    kldl=0\n","    cl=0\n","    recl=0\n","    # Training\n","    print(\"Epoch :\", epoch+1)\n","\n","    #itr = (training_set.__len__()) // batch_size\n","    #print(type(training_generator))\n","    #print(itr,len(training_generator.dataset))\n","    \n","    if __name__ == \"__main__\":\n","        for local_batch, local_labels in trainloader:\n","            cn = cn+1\n","            # Transfer to GPU\n","            local_batch, local_labels = local_batch.to(device,non_blocking=True), local_labels.to(device,non_blocking=True)\n","            #local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n","            optimizer.zero_grad()\n","\n","\n","            optimizer_vae.zero_grad()\n","         \n","            # forward + backward + optimize\n","            c1,outputs = model(local_batch)\n","            \n","            c1=c1.detach()\n","            if  torch.isnan(c1).any(): print(torch.isnan(c1).any())\n","            if  torch.isinf(c1).any(): print(torch.isinf(c1).any())\n","            #c1=torch.randn(64,256,8,8).to(device)\n","            recon_batch, mu, logvar = model_vae(c1)\n","            recon_loss,bce,kld= loss_function(recon_batch,c1 , mu, logvar) #.item()\n","            #print(VAE_LOSS.item())\n","            cl_loss=criterion(outputs, local_labels)\n","            loss_total = cl_loss+recon_loss\n","            loss,loss_vae= loss_total,loss_total\n","            \n","            #vae_loss.append((epoch+1,cn,VAE_LOSS.item(),cl_loss.item(),bce.item(),kld.item()))\n","            loss.backward(retain_graph=True)\n","            loss_vae.backward()\n","\n","            vae_train_loss+=loss_vae.item()*local_batch.size(0)\n","            kldl+=kld.item()*local_batch.size(0)\n","            bnce+=bce.item()*local_batch.size(0)\n","            cl+=cl_loss.item()*local_batch.size(0)\n","            recl+=recon_loss.item()*local_batch.size(0)\n","\n","            optimizer.step()\n","            #torch.nn.utils.clip_grad_norm_(model_vae.parameters(), 5)\n","            optimizer_vae.step()\n","    if vae_train_loss <= train_loss_min:\n","        \n","        for filename in glob.glob(\"model_*\"):\n","            os.remove(filename)\n","        torch.save(model.state_dict(), 'model_vgg_best_epoch'+str(epoch+1)+'.pt')\n","        torch.save(model_vae.state_dict(), 'model_vae_best_epoch'+str(epoch+1)+'.pt')\n","        train_loss_min = vae_train_loss\n","\n","    L=len(trainloader.dataset)\n","    print(recl,L)\n","    avg_loss_recl=recl/ L\n","    avg_loss_cl= cl/L\n","    avg_loss_kld= kldl/L\n","    avg_loss_bce=bnce/L\n","    #print(\" vae loss =\", avg_loss)\n","    epoch_loss.append((epoch+1,avg_loss_recl,avg_loss_cl,avg_loss_bce,\n","                       avg_loss_kld))\n","    print(\"epoch {} , recon loss {} , bce loss {} , kld {}\",epoch+1,avg_loss_recl,avg_loss_bce, avg_loss_kld)\n","    #print(\" vae loss =\", vae_train_loss/ 5)\n","    #break\n","\n","\n","with open('cifar_vae_loss_final.csv', mode='w') as employee_file:\n","    employee_writer = csv.writer(employee_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","    employee_writer.writerow([\"Epoch\",\"classifaction_loss\",\"reconstruction_loss\",\"mse_loss\",\"KLD_loss\"])\n","    for epoch,vloss,clloss,mse,kld in epoch_loss:\n","        employee_writer.writerow([str(epoch),str(clloss),str(vloss),str(mse),str(kld)])\n","        \n","qw=time.time()-start\n","print(qw/3600)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch : 1\n","3214055.5247802734 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 1 83.69936262448628 3.1320688084761303 80.56729382832845\n","Epoch : 2\n","550807.5988464355 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 2 14.343947886625926 2.17245763361454 12.171490227381389\n","Epoch : 3\n","134233.56314086914 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 3 3.495665706793467 2.2269965509573617 1.268669168750445\n","Epoch : 4\n","88321.40962219238 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 4 2.30003670891126 2.1067908086379368 0.19324590012431145\n","Epoch : 5\n","82063.0375289917 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 5 2.1370582689841586 2.0735902508099873 0.063468020906051\n","Epoch : 6\n","79266.73678588867 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 6 2.0642379371325177 2.034882978796959 0.02935496047139168\n","Epoch : 7\n","80553.25141906738 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 7 2.0977409223715466 2.080593395233154 0.017147526542345682\n","Epoch : 8\n","80380.78429412842 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 8 2.0932495909929276 2.0828521688779196 0.010397420277198156\n","Epoch : 9\n","81578.17401123047 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 9 2.1244316148757934 2.117267193198204 0.007164419492085775\n","Epoch : 10\n","83717.04042053223 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 10 2.18013126095136 2.1758986844619117 0.00423257162173589\n","Epoch : 11\n","85424.00858306885 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 11 2.2245835568507513 2.221330880522728 0.003252679854631424\n","Epoch : 12\n","88633.07409667969 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 12 2.3081529712677002 2.305813761750857 0.0023392153282960257\n","Epoch : 13\n","92843.4492263794 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 13 2.4177981569369633 2.41587271074454 0.0019254471858342489\n","Epoch : 14\n","97835.30224609375 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 14 2.547794329325358 2.546084499557813 0.001709824154774348\n","Epoch : 15\n","99443.24211883545 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 15 2.58966776351134 2.5875944922367733 0.002073267598946889\n","Epoch : 16\n","104474.27030944824 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 16 2.7206841226418814 2.715248181025187 0.005435941765705744\n","Epoch : 17\n","114291.17520141602 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 17 2.976332687536875 2.970610245863597 0.005722439338763555\n","Epoch : 18\n","121095.10247802734 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 18 3.1535182936986286 3.148491418361664 0.0050268750389417015\n","Epoch : 19\n","131263.5813446045 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 19 3.4183224308490754 3.4156702371438343 0.0026521927615006766\n","Epoch : 20\n","138195.00540161133 38400\n","epoch {} , recon loss {} , bce loss {} , kld {} 20 3.5988282656669615 3.596755237579346 0.002073030173778534\n","0.4522273388173845\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sje_32AEVX9t"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFQ06TlxBEbh","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594223733743,"user_tz":-360,"elapsed":2138,"user":{"displayName":"Kishor Kumar Bhaumik","photoUrl":"","userId":"10041133773810708456"}},"outputId":"dec5c658-df21-43ea-9ba9-95575dbeabbb"},"source":["if  torch.isnan(c1).any():\n","  print(torch.isnan(c1).any())\n","P= torch.tensor([[1,2,3],[4,5,float('-inf')]])\n","if  torch.isinf(P).any(): print(torch.isinf(P).any())\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor(True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Avr1Ctyy7I7a"},"source":["import pandas as pd\n","df=pd.read_csv('cifar_vae_loss_final.csv')"],"execution_count":null,"outputs":[]}]}